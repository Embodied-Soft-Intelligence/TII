<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer</title>

  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">

  <meta name="description" content="D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer" />

  <style>
    :root{--accent:#6366f1;--muted:#6b7280}
    body{
      font-family:Inter,ui-sans-serif,system-ui;
      background:linear-gradient(180deg,#fbfdff 0%, #f3f6ff 100%);
      color:#0f172a
    }
    .container{max-width:1200px}
    .shadow-soft{box-shadow:0 8px 30px rgba(15,23,42,0.06)}
    .glass{background:rgba(255,255,255,0.75);backdrop-filter:blur(6px)}
    .figure-img{max-height:520px;object-fit:contain}
    p, td, th{text-align:justify}
    table{font-size:0.8rem}
    th,td{text-align:center;padding:6px 8px}
    .uniform-width{max-width:1000px;margin:auto}
    img,video{border:none;outline:none}
  </style>
</head>

<body class="antialiased">

<!-- NAV -->
<nav class="border-b bg-white/60 sticky top-0 backdrop-blur z-40">
  <div class="container mx-auto px-5 py-3 flex justify-between items-center">
    <div class="flex gap-3 items-center">
      <div class="w-10 h-10 rounded-lg bg-indigo-500 text-white flex items-center justify-center font-bold">D2</div>
      <div>
        <div class="text-sm font-semibold">D2TriPO-DETR</div>
        <div class="text-xs text-gray-500">Dual-Decoder Triple-Parallel-Output DETR</div>
      </div>
    </div>
    <div class="hidden md:flex gap-6 text-sm">
      <a href="#fig1">Schematic</a>
      <a href="#results">Results</a>
      <a href="#summary">Experiment</a>
      <a href="#video">Video</a>
    </div>
  </div>
</nav>

<!-- HEADER -->
<header class="container mx-auto px-5 py-10 text-center">
  <h1 class="text-4xl font-extrabold">
    D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer
  </h1>

  <div class="mt-6">
    <a href="https://github.com/Embodied-Soft-Intelligence/TII"
       class="px-6 py-3 bg-indigo-500 text-white rounded-lg">
       Code
    </a>
  </div>

  <p class="mt-6 glass p-4 rounded shadow-soft uniform-width">
    We propose <strong>D2TriPO-DETR</strong>, a dual-decoder transformer that outputs object detection,
    manipulation relationship, and grasp detection in parallel, inspired by human distributed
    perception and visual adaptation mechanisms. The framework alleviates error propagation and
    significantly improves stacked-scene grasping performance.
  </p>
</header>

<main class="container mx-auto px-5 pb-16">

<!-- FIG 1 -->
<section id="fig1" class="text-center mt-8">
  <div class="bg-white p-4 rounded-lg shadow-soft uniform-width">
    <img src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/1.png"
         class="w-full figure-img rounded">
    <p class="text-sm text-gray-600 mt-2">
      Human visual attention characteristics and overall schematics of D2TriPO-DETR.
    </p>
  </div>
</section>

<!-- REAL-WORLD EXPERIMENT -->
<section id="summary" class="mt-12 bg-white p-6 rounded-lg shadow-soft uniform-width">
  <h3 class="font-semibold text-xl mb-3">Real-World Experiment</h3>
  <p>
    The system performs cluttered and stacked grasping by reasoning about manipulation order.
    Object relations are encoded into an adjacency matrix and iteratively updated to ensure
    stable grasp sequences.
  </p>
</section>

<!-- FIG 6 -->
<section class="mt-10 text-center uniform-width">
  <div class="bg-white p-6 rounded-lg shadow-soft">
    <img src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/6.png"
         class="w-full figure-img rounded">
    <p class="text-sm text-gray-600 mt-2">
      Real-world robotic grasping experiments in cluttered and stacked scenarios.
    </p>
  </div>
</section>

<!-- RESULTS -->
<section id="results" class="mt-12 uniform-width">
  <div class="bg-white p-6 rounded-lg shadow-soft">
    <h4 class="font-semibold mb-4 text-center">Model Results</h4>
    <table class="w-full border">
      <tr><th>Model</th><th>Cluttered</th><th>Stacked</th></tr>
      <tr><td>EGNet</td><td>93.60</td><td>69.60</td></tr>
      <tr class="font-semibold bg-indigo-50">
        <td>D2TriPO-DETR</td><td>95.71</td><td>74.29</td>
      </tr>
    </table>
  </div>
</section>

<!-- STABILITY -->
<section class="mt-12 grid grid-cols-1 md:grid-cols-2 gap-6 uniform-width">
  <div class="bg-white p-6 rounded-lg shadow-soft">
    <img src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/S3.png"
         class="w-full figure-img rounded">
    <p class="text-sm text-gray-600 mt-2">
      Stability evaluation with repeated grasping trials.
    </p>
  </div>
  <div class="glass p-6 rounded-lg shadow-soft">
    <h4 class="font-semibold mb-2">Stability Evaluation</h4>
    <p>
      Repeated experiments (30 trials per setting) demonstrate consistent success rates
      as object numbers increase.
    </p>
  </div>
</section>

<!-- ROBUSTNESS -->
<section class="mt-12 grid grid-cols-1 md:grid-cols-2 gap-6 uniform-width">
  <div class="bg-white p-6 rounded-lg shadow-soft">
    <img src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/S4.png"
         class="w-full figure-img rounded">
    <p class="text-sm text-gray-600 mt-2">
      Boundary ambiguity scenarios: occlusion, color similarity, and insertion.
    </p>
  </div>
  <div class="glass p-6 rounded-lg shadow-soft">
    <h4 class="font-semibold mb-2">Robustness under Boundary Ambiguity</h4>
    <p>
      The model maintains reliable grasp planning under ambiguous boundaries,
      enabling successful execution in challenging real-world scenes.
    </p>
  </div>
</section>

<!-- VIDEO -->
<section id="video" class="mt-12 uniform-width">
  <h3 class="font-semibold text-xl text-center mb-6">
    Demonstration Videos — Real Robot Experiments
  </h3>

  <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
    <div class="bg-white p-4 rounded-lg shadow-soft text-center">
      <video controls class="w-full rounded mb-2">
        <source src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/Mov.%201.mp4">
      </video>
      <p class="text-sm text-gray-600">Stacked scene grasping experiments</p>
    </div>

    <div class="bg-white p-4 rounded-lg shadow-soft text-center">
      <video controls class="w-full rounded mb-2">
        <source src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/Mov.%202.mp4">
      </video>
      <p class="text-sm text-gray-600">Cluttered scene grasping experiments</p>
    </div>

    <div class="bg-white p-4 rounded-lg shadow-soft text-center">
      <video controls class="w-full rounded mb-2">
        <source src="https://raw.githubusercontent.com/Embodied-Soft-Intelligence/TII/main/picture/Mov.%203.mp4">
      </video>
      <p class="text-sm text-gray-600">
        Experiments for Special Cases Exceeding the Numberof Stacked Objects in the Dataset
      </p>
    </div>
  </div>
</section>

<footer class="mt-12 text-center text-sm text-gray-500 uniform-width">
  © 2025 D2TriPO-DETR — Research Demonstration
</footer>

</main>
</body>
</html>
